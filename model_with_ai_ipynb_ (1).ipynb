{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SAGSIrNhBCZC",
        "outputId": "5dd001b2-ebe4-40ab-f1b5-df0519ae8042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.10/dist-packages (2.9.9)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.31)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install psycopg2-binary sqlalchemy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OkWl-1wnFgV-",
        "outputId": "a3a6ce8f-9e5d-4340-86e2-3731cf0c11c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==1.0.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.0.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.2->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.2->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (2.2.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.22.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "smg9lKTVFgnR"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DzhyWjddGRMW"
      },
      "outputs": [],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QxMA-3eiGTcQ"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cu37g68pTh2m"
      },
      "outputs": [],
      "source": [
        "!pip install deep-translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9ynZMiWWRUc"
      },
      "outputs": [],
      "source": [
        "from deep_translator import GoogleTranslator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaP6iRnbBI4m"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine, Column, Integer, String, DateTime, Float\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from datetime import datetime\n",
        "import os\n",
        "import openai\n",
        "import requests\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "from transformers import AutoConfig\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wzx9xmEGFbDG"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8SEHFbjFcQi"
      },
      "outputs": [],
      "source": [
        "#модель для детекции\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"rabiaqayyum/autotrain-mental-health-analysis-752423172\", use_auth_token=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"rabiaqayyum/autotrain-mental-health-analysis-752423172\", use_auth_token=True)\n",
        "config = AutoConfig.from_pretrained(\"rabiaqayyum/autotrain-mental-health-analysis-752423172\", use_auth_token=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6Ka3inIGZEQ"
      },
      "outputs": [],
      "source": [
        "class_labels = [config.id2label[i] for i in range(len(config.id2label))]\n",
        "depression_threshold = 0.9\n",
        "message_history = []\n",
        "anomaly_detected = False\n",
        "message_chat_history=[]\n",
        "value_crystal = 0\n",
        "visible_flg = False\n",
        "mascots = [\"Kiko\", 'Lori']\n",
        "openai.api_key = \"xxxx\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mYzVMjoGpgv"
      },
      "source": [
        "# Функции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cinDDGdrBg9e"
      },
      "outputs": [],
      "source": [
        "# модель детекции\n",
        "def classify_message(user_message, message_history):\n",
        "    #session = SessionLocal()\n",
        "   # try:\n",
        "    detected_lang = user_message\n",
        "    translated_message = user_message\n",
        "    inputs = tokenizer([user_message], return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    probabilities = outputs.logits.softmax(dim=-1)\n",
        "    predicted_class_indices = probabilities.argmax(dim=-1)\n",
        "    depression_probability = probabilities[0][class_labels.index(\"depression\")].item()\n",
        "\n",
        "    if predicted_class_indices.item() == class_labels.index(\"depression\") and depression_probability < depression_threshold:\n",
        "        predicted_class = \"mentalhealth\"\n",
        "    else:\n",
        "        predicted_class = class_labels[predicted_class_indices.item()]\n",
        "\n",
        "    #сохранение сообщения в бд\n",
        "    #сuser_message_record = UserMessages(user_id=1, message=user_message, classification=predicted_class)\n",
        "    #с session.add(user_message_record)\n",
        "    #сsession.commit()\n",
        "\n",
        "    message_history.append(predicted_class)\n",
        "    mental_state_count = sum(1 for msg in message_history if msg != \"mentalhealth\")\n",
        "\n",
        "    if mental_state_count > 10:\n",
        "        if mental_state_count > 10:\n",
        "          warning_message = \"\"\"We noticed you've been sharing some thoughts that might indicate you're going through a tough time. We recommend seeking help from a professional.\n",
        "          Sources utiles:\n",
        "          https://findahelpline.com/\n",
        "          https://www.mind.org.uk/\n",
        "          https://www.headspace.com/\"\"\"\n",
        "        return warning_message, True\n",
        "\n",
        "    return None, False\n",
        "    #finally:\n",
        "       # session.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P2tWyPOG00P"
      },
      "source": [
        "Ответ модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlT4zIJ2G2Ox"
      },
      "outputs": [],
      "source": [
        "def respond(user_message, message_history, mascot):\n",
        "    prompt = f\"You are a {mascot}, you are a wise cat helping people improve their mental health. Here is a message from the user: {user_message}. \\\n",
        "    Answer according to your character. Answer in the same language that the user writes in. \\\n",
        "    The first message you send will always be the same: Hello! My name is {mascot}, \\\n",
        "    I am your friend and assistant. We have credited you 1 crystal for admission. \\\n",
        "    Keep it up ! I will be glad to help! How are you feeling today?\"\n",
        "    history_messages = \" \".join(message_history)\n",
        "    prompt_with_history = f\"{prompt}\\n{history_messages}\\n User: {user_message}\\n\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_with_history}]\n",
        "    )\n",
        "\n",
        "    #обновление кристаллов\n",
        "    #session = SessionLocal()\n",
        "   # try:\n",
        "    #    #crystal_record = session.query(Crystals).filter(Crystals.user_id == 1).first()\n",
        "    #    if crystal_record:\n",
        "     #       crystal_record.crystal_count += 1\n",
        "      #  else:\n",
        "       #     crystal_record = Crystals(user_id=1, crystal_count=1)\n",
        "        #    session.add(crystal_record)\n",
        "       # session.commit()\n",
        "    #finally:\n",
        "     #   session.close()\n",
        "\n",
        "    return response['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm-w95mNHB8i"
      },
      "source": [
        "Интерфейс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsB8cU8oG7Eh"
      },
      "outputs": [],
      "source": [
        "def chatbot_interface(user_message, mascot_choice):\n",
        "    global anomaly_detected, message_history, value_crystal, visible_flg\n",
        "\n",
        "    if not user_message.strip():\n",
        "        return \"Enter your message here\", None\n",
        "\n",
        "    if not anomaly_detected:\n",
        "        warning_message, anomaly_detected = classify_message(user_message, message_history)\n",
        "        if anomaly_detected:\n",
        "            message_chat_history.extend([f\"I: {user_message}\", f\"{mascot_choice}: {warning_message}\"])\n",
        "            return  None, '\\n'.join(message_chat_history)\n",
        "    if len(message_chat_history) == 0:\n",
        "      value_crystal=int(value_crystal.value)+1\n",
        "      visible_flg = True\n",
        "    response_message = respond(user_message, message_history, mascot_choice)\n",
        "    message_history.extend([f\"User: {user_message}\", f\"{mascot_choice}: {response_message}\"])\n",
        "    if \"Lori:\" in response_message or \"Kiko:\" in response_message:\n",
        "      response_message = response_message.replace(\"Lori:\", \"\")\n",
        "      response_message =  response_message.replace(\"Kiko:\", \"\")\n",
        "    message_chat_history.extend([f\"I: {user_message}\", f\"{mascot_choice}: {response_message}\"])\n",
        "    return  None, '\\n'.join(message_chat_history), value_crystal, visible_flg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWmY6LovHHPk"
      },
      "source": [
        "Визуализируем бота"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "-zpECoTOHD-p",
        "outputId": "09a1a1fc-8bcd-438b-aa41-7a7767db5992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://77b3d25a2ab2f79ede.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://77b3d25a2ab2f79ede.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with gr.Blocks() as iface:\n",
        "    with gr.Row():\n",
        "        gr.Image(\"/content/cristall.png\", show_label=False, width=12, height=80, show_download_button = False, visible = True)\n",
        "        value_crystal = gr.Textbox(label=\"💎(your crystal count)\", value = 0, autoscroll=False)\n",
        "    gr.Markdown(\"# Chatbot for mental health\")\n",
        "    gr.Image(\"/content/logo.jfif\", show_label=False, width=2, height=150, show_download_button = False)\n",
        "    gr.Markdown(\"# Select a mascot, enter your message to get support and say hi for me :)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            mascot_choice = gr.Dropdown(choices=mascots, label=\"Choose a mascot\", elem_id=\"mascot-dropdown\")\n",
        "            user_message = gr.Textbox(label = 'Enter message ♡', lines=2, placeholder=\"Enter your message here...\", elem_id=\"chat-message\")\n",
        "            submit_btn = gr.Button(\"Send\")\n",
        "        with gr.Column(scale=1):\n",
        "            mascot_image = gr.Image(label=\"Mascot\", elem_id=\"mascot-image\", show_download_button = False, show_label = False)\n",
        "\n",
        "    chat_history = gr.Textbox(label=\"Chat\")\n",
        "\n",
        "    def update_mascot(mascot):\n",
        "        return f\"/content/{mascot}.gif\"\n",
        "\n",
        "\n",
        "    mascot_choice.change(\n",
        "        fn=update_mascot,\n",
        "        inputs=[mascot_choice],\n",
        "        outputs=[mascot_image]\n",
        "    )\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=chatbot_interface,\n",
        "        inputs=[user_message, mascot_choice],\n",
        "        outputs=[user_message, chat_history, value_crystal]\n",
        "    )\n",
        "iface.launch(debug = True)\n",
        "#iface.launch(auth=('user', 'admin'), auth_message=\"Enter your username and password, please\", share=True, debug = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AdfGOQoXd7u"
      },
      "source": [
        "# новая функция детекции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvC0_o3MWYGk"
      },
      "outputs": [],
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def classify_message(user_message, message_history):\n",
        "    #session = SessionLocal()\n",
        "    detected_language = GoogleTranslator(source='auto', target='en').detect(user_message)\n",
        "    try:\n",
        "        # Перевод сообщения на английский язык\n",
        "        translated_message = GoogleTranslator(source='auto', target='en').translate(user_message)\n",
        "\n",
        "        inputs = tokenizer([translated_message], return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        outputs = model(**inputs)\n",
        "        probabilities = outputs.logits.softmax(dim=-1)\n",
        "        predicted_class_indices = probabilities.argmax(dim=-1)\n",
        "        depression_probability = probabilities[0][class_labels.index(\"depression\")].item()\n",
        "\n",
        "        if predicted_class_indices.item() == class_labels.index(\"depression\") and depression_probability < depression_threshold:\n",
        "            predicted_class = \"mentalhealth\"\n",
        "        else:\n",
        "            predicted_class = class_labels[predicted_class_indices.item()]\n",
        "\n",
        "        #сохранение сообщения в бд\n",
        "        #user_message_record = UserMessages(user_id=1, message=user_message, classification=predicted_class)\n",
        "        #session.add(user_message_record)\n",
        "        #session.commit()\n",
        "\n",
        "        message_history.append(predicted_class)\n",
        "        mental_state_count = sum(1 for msg in message_history if msg != \"mentalhealth\")\n",
        "\n",
        "        if mental_state_count > 10:\n",
        "            if mental_state_count > 10:\n",
        "              warning_message = \"We noticed you've been sharing some thoughts that might indicate you're going through a tough time. We recommend seeking help from a professional.\"\n",
        "              translated_warning = GoogleTranslator(source='en', target=detected_language).translate(warning_message)\n",
        "\n",
        "              sourc = \"\"\"Sources utiles:\n",
        "              https://findahelpline.com/\n",
        "              https://www.mind.org.uk/\n",
        "              https://www.headspace.com/\"\"\"\n",
        "              mes_for_user = translated_warning + \"\\n\\n\" + sourc\n",
        "            return mes_for_user, True\n",
        "\n",
        "        return None, False\n",
        "    finally:\n",
        "        #session.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYveCbNCyIOT"
      },
      "outputs": [],
      "source": [
        "def respond(user_message, message_history, mascot):\n",
        "    if not message_history:\n",
        "        prompt = f\"You are a {mascot}, you are a wise cat helping people improve their mental health. The first message you send will always be the same: Hello! My name is {mascot}, I am your friend and assistant. We have credited you 1 crystal for admission. Keep it up! I will be glad to help! How are you feeling today?\"\n",
        "    else:\n",
        "        prompt = f\"You are a {mascot}, you are a wise cat helping people improve their mental health. Here is a message from the user: {user_message}. Answer according to your character. Answer in the same language that the user writes in.\"\n",
        "\n",
        "    history_messages = \" \".join(message_history)\n",
        "    prompt_with_history = f\"{prompt}\\n{history_messages}\\n User: {user_message}\\n\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_with_history}]\n",
        "    )\n",
        "\n",
        "    #обновление кристаллов\n",
        "    #session = SessionLocal()\n",
        "    try:\n",
        "        #crystal_record = session.query(Crystals).filter(Crystals.user_id == 1).first()\n",
        "        if crystal_record:\n",
        "            crystal_record.crystal_count += 1\n",
        "        else:\n",
        "            crystal_record = Crystals(user_id=1, crystal_count=1)\n",
        "            session.add(crystal_record)\n",
        "        session.commit()\n",
        "    finally:\n",
        "        session.close()\n",
        "\n",
        "    return response['choices'][0]['message']['content']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}